{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot Github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlLJ78ohEhV9"
      },
      "source": [
        "# **Part 1 - Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bs81Hvh9tRF"
      },
      "source": [
        "import pickle\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnwJAfJ3GG2c"
      },
      "source": [
        "**1.1 Loading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzirYdsCEmWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97be16a8-d94b-4206-db66-b6b70200ec67"
      },
      "source": [
        "with open('train_qa.txt', 'rb') as f:\r\n",
        "  train_data = pickle.load(f) #using pickle to load in the training file, read in as binary\r\n",
        "\r\n",
        "with open('test_qa.txt', 'rb') as f:\r\n",
        "  test_data = pickle.load(f) #using pickle to load in the test file, read in as binary\r\n",
        "\r\n",
        "type(train_data) #see it's a list"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr4QptJJFIY3",
        "outputId": "663a87c3-6346-4aa8-c72b-1cfd5e4a3dcb"
      },
      "source": [
        "print(len(train_data)) #10000 data points broken up into story,question,answer\r\n",
        "print(len(test_data)) #1000 data points broken up into story,question,answer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ9kKiIlFWsQ",
        "outputId": "3341199f-390c-460c-b91b-b11b09aef0b0"
      },
      "source": [
        "#so here we can see this tuple has 3 main components: story, question, answer\r\n",
        "print(' '.join(train_data[0][0])) #index 0 is the story\r\n",
        "print(' '.join(train_data[0][1])) #index 1 is the question\r\n",
        "print(train_data[0][2]) #index 2 is the answer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mary moved to the bathroom . Sandra journeyed to the bedroom .\n",
            "Is Sandra in the hallway ?\n",
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_saaTUQHHygV",
        "outputId": "dcfd9f22-2686-44e8-d273-45fbfc7513bf"
      },
      "source": [
        "#Next step we'll want to grab all the unique words\r\n",
        "all_data = test_data + train_data #concatenating our test data with our train data\r\n",
        "all_data_np = np.array(all_data) #converting all our data into a numpy array\r\n",
        "all_data_np.shape #notice the shape of the numpy array is 11000 rows (10000 train + 1000 test data points) and 3 columns (story, question, answer)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBAII3MnGmqM"
      },
      "source": [
        "**1.2 Grabbing the Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi4uEVNDGDU1"
      },
      "source": [
        "vocab = set() #initializing vocab. set removes duplicates and only returns each distinct element once \r\n",
        "\r\n",
        "#Now we're going to grab all the unique vocabulary\r\n",
        "for story, question, answer in all_data:\r\n",
        "  vocab = vocab.union(set(story)) #set removes duplicates\r\n",
        "  vocab = vocab.union(set(question)) #union just allows us to join the different sets together. So far, we have a set for story and an initialized set, so now we're using union to add our question set to vocab. https://www.w3schools.com/python/ref_set_union.asp\r\n",
        "\r\n",
        "vocab.add('no')\r\n",
        "vocab.add('yes')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s89AKa4BHZms",
        "outputId": "1baa13e8-ec7f-4c08-fad6-304d971fe750"
      },
      "source": [
        "print(' '.join(vocab)) #showing all the different vocabulary in one line\r\n",
        "print(len(vocab)) #see how there are only 37 unique words in total\r\n",
        "#note that means when creating new sentences and predictions, only these 37 words can be used. No new words can be introduced, as the model was not trained on them"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "football moved Is no . left up in milk kitchen John yes got grabbed dropped Mary to discarded bathroom took Sandra garden office there put went bedroom travelled down journeyed the apple Daniel hallway ? back picked\n",
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGou9pmdflxW",
        "outputId": "e3dcac05-3a97-44de-b536-c01b33297b26"
      },
      "source": [
        "vocab_size = len(vocab) + 1 #adding 1 cuz keras padding needs an extra one to hold a zero\r\n",
        "vocab_size"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N8mXF1SIi9W"
      },
      "source": [
        "**1.3 Longest Story and Longest Question**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMBFyZzlIW6n",
        "outputId": "e88b7aca-7744-4c0f-9b65-9f343ec5e2a3"
      },
      "source": [
        "#Longest Story\r\n",
        "all_story_lens = [len(data[0]) for data in all_data] #data[0] is the story, data[1] is the question, data[2] is the answer\r\n",
        "max_story_len = max(all_story_lens) \r\n",
        "max_story_len #156 is the longest story\r\n",
        "\r\n",
        "#so we need the longest length because the RNN requires the text inputs to be the same length. As such, for the shorter stories, we'll use padding sequences to pad the text with 0s until it reaches the max story length"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBFe3j4yJEyx",
        "outputId": "6944339a-2929-4c62-be3a-31d00777add6"
      },
      "source": [
        "#Longest Question\r\n",
        "all_question_lens = [len(question) for story, question, answer in all_data] #could've also just used tuple unpacking in contrast to above\r\n",
        "max_question_len = max(all_question_lens) \r\n",
        "max_question_len #6 is the longest question\r\n",
        "\r\n",
        "#so we need the longest length because the RNN requires the text inputs to be the same length. As such, for the shorter questions, we'll use padding sequences to pad the text with 0s until it reaches the max question length"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l3ZR0uMbf_a"
      },
      "source": [
        "# **Part 2 - Vectorizing the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yywXYGhleUyI"
      },
      "source": [
        "**2.1 Tokenizing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kcuAagmJVZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065003cf-8466-46c2-dc18-4356b0b061f3"
      },
      "source": [
        "#creating an integer encoding our sequence of words\r\n",
        "tokenizer = Tokenizer(filters=[]) #creating an instance of our tokenizer imported above\r\n",
        "tokenizer.fit_on_texts(vocab) #tokenizing our vocabulator. fitting our vocabulary to the tokenizer, so each word will be assigned a token number \r\n",
        "\r\n",
        "tokenizer.word_index #dictionary of the word and index, words are all automatically lowercased for us too now"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 5,\n",
              " '?': 35,\n",
              " 'apple': 32,\n",
              " 'back': 36,\n",
              " 'bathroom': 19,\n",
              " 'bedroom': 27,\n",
              " 'daniel': 33,\n",
              " 'discarded': 18,\n",
              " 'down': 29,\n",
              " 'dropped': 15,\n",
              " 'football': 1,\n",
              " 'garden': 22,\n",
              " 'got': 13,\n",
              " 'grabbed': 14,\n",
              " 'hallway': 34,\n",
              " 'in': 8,\n",
              " 'is': 3,\n",
              " 'john': 11,\n",
              " 'journeyed': 30,\n",
              " 'kitchen': 10,\n",
              " 'left': 6,\n",
              " 'mary': 16,\n",
              " 'milk': 9,\n",
              " 'moved': 2,\n",
              " 'no': 4,\n",
              " 'office': 23,\n",
              " 'picked': 37,\n",
              " 'put': 25,\n",
              " 'sandra': 21,\n",
              " 'the': 31,\n",
              " 'there': 24,\n",
              " 'to': 17,\n",
              " 'took': 20,\n",
              " 'travelled': 28,\n",
              " 'up': 7,\n",
              " 'went': 26,\n",
              " 'yes': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDNq-QgKjPPI"
      },
      "source": [
        "**2.2 Vectorizing Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39tRz5M7gk4B"
      },
      "source": [
        "def vectorize(data, word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_len = max_question_len):\r\n",
        "  X = [] #X = stories\r\n",
        "  Xq = [] #Xq = questions\r\n",
        "  Y = [] #Y = answer\r\n",
        "\r\n",
        "  for story, question, answer in data:\r\n",
        "    #so for each story and question, first we're lowercasing each word, then we're converting each word into its tokenized index rather than appending the string\r\n",
        "    #for example word_index['apple'] will return the token index of 3 rather than the word apple\r\n",
        "    x = [word_index[word.lower()] for word in story] #lowercase x = each individual story entry where each word is replaced by the token index\r\n",
        "    xq = [word_index[word.lower()] for word in question] #lowercase xq = each individual question entry where each word is replaced by the token index\r\n",
        "\r\n",
        "    y = np.zeros(len(word_index)+1) #+1 because index 0 is reserved when using pad sequences. So length of all the words is 37, plus padding is equal to 38\r\n",
        "    y[word_index[answer]] = 1 #so for this story, appending the answer to this word\r\n",
        "\r\n",
        "    X.append(x) #appending the stories to a list\r\n",
        "    Xq.append(xq) #appending the questions to a list\r\n",
        "    Y.append(y) #appending all the answers to the questions\r\n",
        "  \r\n",
        "  return (pad_sequences(sequences = X, maxlen = max_story_len), pad_sequences(sequences = Xq, maxlen = max_question_len), np.array(Y)) \r\n",
        "  #we imported pad_sequences above and all it does it just pad the sequences to the maximum length, such that they can all be the same size which is a requirement when feeding into our RNN. also returning our label"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE1kH5x4oK7w"
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize(train_data)\r\n",
        "\r\n",
        "inputs_test, queries_test, answers_test = vectorize(test_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6vVtdV2o783",
        "outputId": "5ac36ccf-1822-413b-b77f-d35148fe4740"
      },
      "source": [
        "print(queries_test) #notice the questions are now replaced by their tokenized index and max length is 6. The first word for the ones in the preview is \"Is\"=3, as expected from a question \r\n",
        "print(tokenizer.word_index['the'], '= the \\n', tokenizer.word_index['bedroom'], '= bedroom \\n',tokenizer.word_index['is'], '= is')\r\n",
        "#so these are just arrays with stories outlining the word index position and word index"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3 11  8 31 10 35]\n",
            " [ 3 11  8 31 10 35]\n",
            " [ 3 11  8 31 22 35]\n",
            " ...\n",
            " [ 3 16  8 31 27 35]\n",
            " [ 3 21  8 31 22 35]\n",
            " [ 3 16  8 31 22 35]]\n",
            "31 = the \n",
            " 27 = bedroom \n",
            " 3 = is\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vb167HTpHQa",
        "outputId": "2ff471ab-07fe-4d44-a2c8-3f95aadefdf0"
      },
      "source": [
        "sum(answers_test) #so 497 cases of yes (token index 12) and 503 cases of no (token index 4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJNHLW0tt3C2"
      },
      "source": [
        "# **Part 3 - Building the End to End Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk_VD6Rqqk2H"
      },
      "source": [
        "#so we have 2 inputs: stories and questions. So the encoder needs to understand the story, then a separate question, and then we have to link them together in order to provide a label (yes or no)\r\n",
        "#so first we're going to create placeholders using Input to instantiate (create an instance of) a keras tensor\r\n",
        "input_sequence = Input(shape = (max_story_len, )) #so creating an instance of Input, which was imported above.\r\n",
        "#Shape will be based off max story length and max question length, since stories & questions are our two inputs. \r\n",
        "#We added a comma, because since this is a placeholder, the shape will take in (max_story_len, batch_size) where batch_size is currently unknown, so we'll leave it TBD\r\n",
        "\r\n",
        "question = Input(shape=(max_question_len, ))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpBTRNbWwY7G",
        "outputId": "13d88b0c-3c9f-4a38-c384-d29d72237963"
      },
      "source": [
        "vocab_size #recall we defined vocab_size earlier above as the len(vocab) + 1, where the +1 is the padding the zero"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huv3IuuswMXa"
      },
      "source": [
        "**3.1 Input Encoder, M**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SvwnB6kvw8f"
      },
      "source": [
        "input_encoder_m = Sequential()\r\n",
        "input_encoder_m.add(Embedding(input_dim = vocab_size, output_dim = 64)) #picking 64 as output based off the paper and power of 2\r\n",
        "input_encoder_m.add(Dropout(0.45)) #dropout 45% to reduce overfitting\r\n",
        "#encoder will basically output (samples, story_max_len, embedding_dim)\r\n",
        "#just made a network sequence for this encoder"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCYie-_RxEwN"
      },
      "source": [
        "**3.2 Input Encoder, C**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82R5REtTxHBv"
      },
      "source": [
        "input_encoder_c = Sequential()\r\n",
        "input_encoder_c.add(Embedding(input_dim = vocab_size, output_dim = max_question_len)) \r\n",
        "input_encoder_c.add(Dropout(0.45)) #dropout 45% to reduce overfitting\r\n",
        "# encoder will basically output (samples, story_max_len, max_question_len)\r\n",
        "#just made a network sequence for this encoder"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6tVAYO0xWJr"
      },
      "source": [
        "**3.3 Question Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNK8tt0ExaP9"
      },
      "source": [
        "question_encoder = Sequential()\r\n",
        "question_encoder.add(Embedding(input_dim = vocab_size, output_dim = 64, input_length = max_question_len)) \r\n",
        "question_encoder.add(Dropout(0.45)) #dropout 45% to reduce overfitting\r\n",
        "# encoder will basically output (samples, question_max_len, embedding)\r\n",
        "#just made a network sequence for this encoder"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syxVTQBCzI7R"
      },
      "source": [
        "**3.4 Encoding our Sequences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl5n8gNbx1AR"
      },
      "source": [
        "#Encoder(Input) --> Encoded \r\n",
        "input_encoded_m = input_encoder_m(input_sequence) #passing in that input sequence placeholder we made above into our input encoder m\r\n",
        "input_encoded_c = input_encoder_c(input_sequence) #passing in that input sequence placeholder we made above into our input encoder c\r\n",
        "question_encoded = question_encoder(question) #passing in that question sequence placeholder we made above into our question encoder"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOg72UR3ziuE"
      },
      "source": [
        "**3.5 End to End Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A5F59Ihzax0"
      },
      "source": [
        "#Using a dot product to compute the match between the first input vector sequence and the question\r\n",
        "match = dot([input_encoded_m,question_encoded], axes=(2,2)) #multiplying internal question state, U, with memory state, Mi.\r\n",
        "match = Activation('softmax')(match) #so applying softmax to the product of U-tranposed and Mi to get the weights, Pi"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG1t06HL0gsD"
      },
      "source": [
        "response = add([match, input_encoded_c]) #calculate the weighted sum, O, by taking the product of weights, Pi, with Ci\r\n",
        "response = Permute((2,1))(response) #permuting (converting) to have an output of samples with dimensions query max length by story max length"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRtvgDup1EWK",
        "outputId": "ec6703c0-a085-4959-d4fe-111800287c36"
      },
      "source": [
        "answer = concatenate([response, question_encoded]) #now we're passing weighted sum, O, plus internal question state, u, by concatenating. In just a End-to-End layer, we'd multiply it with final weight matrix, W, then pass through a softmax to get the final label. However, because we're adding an LSTM and RNN, we do that later.\r\n",
        "answer #so see how answer is a Tensorflow tensor, where the shape is (?, 6, 220) where ? = unknown batch size still,"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhskw4wE2bqG"
      },
      "source": [
        "**3.6 LSTM and RNN Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-3xmJU41pk9"
      },
      "source": [
        "#In just a End-to-End layer, we'd multiply the concatenated answer with final weight matrix, W, then pass through a softmax to get the final label. However, because we're adding an LSTM and RNN, we do that later.\r\n",
        "answer = LSTM(32)(answer) #adding LSTM layer\r\n",
        "answer = Dropout(0.45)(answer)\r\n",
        "answer = Dense(vocab_size)(answer) #outputs in the shape of (sample, vocab_size), but we'll just see a 1 on index for yes or no, whereas the rest of the vocabularies will just be 0\r\n",
        "\r\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2IWGCCF3JOY"
      },
      "source": [
        "model = Model(inputs = [input_sequence, question], outputs = answer) #creating an instance of our Model which we imported above\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = 'accuracy')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN1tX90o3mKi",
        "outputId": "1ae5459f-d441-4199-b7bb-13473db21244"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXFpMvAd4Hpr"
      },
      "source": [
        "# **Part 4 - Training our Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SWWryS16o0N"
      },
      "source": [
        "**4.1 Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UTeoB88324a",
        "outputId": "f29c16ea-df97-40a7-931b-c19334a35715"
      },
      "source": [
        "import time #Gonna try to keep track of how long it takes to train our model\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "history = model.fit(x = [inputs_train, queries_train], y = answers_train, batch_size = 32, epochs = 250, validation_data = ([inputs_test, queries_test], answers_test)) #recall inputs train was our list created of the word indexes\r\n",
        "\r\n",
        "print(f'Training took {(time.time() - start_time)/60} minutes')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "313/313 [==============================] - 8s 18ms/step - loss: 1.2946 - accuracy: 0.4808 - val_loss: 0.6979 - val_accuracy: 0.5030\n",
            "Epoch 2/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.7079 - accuracy: 0.5133 - val_loss: 0.6947 - val_accuracy: 0.5030\n",
            "Epoch 3/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6972 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 4/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6947 - accuracy: 0.4960 - val_loss: 0.6947 - val_accuracy: 0.5030\n",
            "Epoch 5/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6944 - accuracy: 0.5115 - val_loss: 0.6966 - val_accuracy: 0.4970\n",
            "Epoch 6/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6945 - accuracy: 0.5005 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 7/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6936 - accuracy: 0.5113 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
            "Epoch 8/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6942 - accuracy: 0.4981 - val_loss: 0.7011 - val_accuracy: 0.4970\n",
            "Epoch 9/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6949 - accuracy: 0.5070 - val_loss: 0.6936 - val_accuracy: 0.5150\n",
            "Epoch 10/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6940 - accuracy: 0.5094 - val_loss: 0.6983 - val_accuracy: 0.4970\n",
            "Epoch 11/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6926 - accuracy: 0.5180 - val_loss: 0.6937 - val_accuracy: 0.4950\n",
            "Epoch 12/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6886 - accuracy: 0.5249 - val_loss: 0.6888 - val_accuracy: 0.5250\n",
            "Epoch 13/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6822 - accuracy: 0.5580 - val_loss: 0.6692 - val_accuracy: 0.5970\n",
            "Epoch 14/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6697 - accuracy: 0.5898 - val_loss: 0.6449 - val_accuracy: 0.6230\n",
            "Epoch 15/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6493 - accuracy: 0.6217 - val_loss: 0.6349 - val_accuracy: 0.6160\n",
            "Epoch 16/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6414 - accuracy: 0.6364 - val_loss: 0.6193 - val_accuracy: 0.6690\n",
            "Epoch 17/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6254 - accuracy: 0.6585 - val_loss: 0.6071 - val_accuracy: 0.6640\n",
            "Epoch 18/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6205 - accuracy: 0.6609 - val_loss: 0.6232 - val_accuracy: 0.6560\n",
            "Epoch 19/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5947 - accuracy: 0.6894 - val_loss: 0.5758 - val_accuracy: 0.7080\n",
            "Epoch 20/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5971 - accuracy: 0.6861 - val_loss: 0.5544 - val_accuracy: 0.7320\n",
            "Epoch 21/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5769 - accuracy: 0.7063 - val_loss: 0.5294 - val_accuracy: 0.7430\n",
            "Epoch 22/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5552 - accuracy: 0.7192 - val_loss: 0.5060 - val_accuracy: 0.7650\n",
            "Epoch 23/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5468 - accuracy: 0.7238 - val_loss: 0.4867 - val_accuracy: 0.7620\n",
            "Epoch 24/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5278 - accuracy: 0.7470 - val_loss: 0.4710 - val_accuracy: 0.7740\n",
            "Epoch 25/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5166 - accuracy: 0.7521 - val_loss: 0.4663 - val_accuracy: 0.7810\n",
            "Epoch 26/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5071 - accuracy: 0.7598 - val_loss: 0.4567 - val_accuracy: 0.7800\n",
            "Epoch 27/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4915 - accuracy: 0.7679 - val_loss: 0.4653 - val_accuracy: 0.7730\n",
            "Epoch 28/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4915 - accuracy: 0.7699 - val_loss: 0.4537 - val_accuracy: 0.7960\n",
            "Epoch 29/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4854 - accuracy: 0.7699 - val_loss: 0.4422 - val_accuracy: 0.7960\n",
            "Epoch 30/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4771 - accuracy: 0.7729 - val_loss: 0.4453 - val_accuracy: 0.7980\n",
            "Epoch 31/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4742 - accuracy: 0.7822 - val_loss: 0.4297 - val_accuracy: 0.7870\n",
            "Epoch 32/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4696 - accuracy: 0.7804 - val_loss: 0.4450 - val_accuracy: 0.7910\n",
            "Epoch 33/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4679 - accuracy: 0.7820 - val_loss: 0.4212 - val_accuracy: 0.8020\n",
            "Epoch 34/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4518 - accuracy: 0.7947 - val_loss: 0.4362 - val_accuracy: 0.8030\n",
            "Epoch 35/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4469 - accuracy: 0.7947 - val_loss: 0.4213 - val_accuracy: 0.8100\n",
            "Epoch 36/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4393 - accuracy: 0.7979 - val_loss: 0.4227 - val_accuracy: 0.8050\n",
            "Epoch 37/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4413 - accuracy: 0.7993 - val_loss: 0.4129 - val_accuracy: 0.8090\n",
            "Epoch 38/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4250 - accuracy: 0.8042 - val_loss: 0.4157 - val_accuracy: 0.8120\n",
            "Epoch 39/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4235 - accuracy: 0.8068 - val_loss: 0.4163 - val_accuracy: 0.7990\n",
            "Epoch 40/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4066 - accuracy: 0.8148 - val_loss: 0.4066 - val_accuracy: 0.8020\n",
            "Epoch 41/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4032 - accuracy: 0.8164 - val_loss: 0.4016 - val_accuracy: 0.8080\n",
            "Epoch 42/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3887 - accuracy: 0.8226 - val_loss: 0.3865 - val_accuracy: 0.8190\n",
            "Epoch 43/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3836 - accuracy: 0.8273 - val_loss: 0.3899 - val_accuracy: 0.8250\n",
            "Epoch 44/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3831 - accuracy: 0.8253 - val_loss: 0.3755 - val_accuracy: 0.8250\n",
            "Epoch 45/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3754 - accuracy: 0.8363 - val_loss: 0.3710 - val_accuracy: 0.8240\n",
            "Epoch 46/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3687 - accuracy: 0.8347 - val_loss: 0.3734 - val_accuracy: 0.8270\n",
            "Epoch 47/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3667 - accuracy: 0.8345 - val_loss: 0.3703 - val_accuracy: 0.8320\n",
            "Epoch 48/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3619 - accuracy: 0.8389 - val_loss: 0.3659 - val_accuracy: 0.8250\n",
            "Epoch 49/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3588 - accuracy: 0.8418 - val_loss: 0.3697 - val_accuracy: 0.8270\n",
            "Epoch 50/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3467 - accuracy: 0.8458 - val_loss: 0.3586 - val_accuracy: 0.8340\n",
            "Epoch 51/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3533 - accuracy: 0.8442 - val_loss: 0.3571 - val_accuracy: 0.8320\n",
            "Epoch 52/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3474 - accuracy: 0.8438 - val_loss: 0.3678 - val_accuracy: 0.8260\n",
            "Epoch 53/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3436 - accuracy: 0.8501 - val_loss: 0.3513 - val_accuracy: 0.8390\n",
            "Epoch 54/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3382 - accuracy: 0.8494 - val_loss: 0.3536 - val_accuracy: 0.8330\n",
            "Epoch 55/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3406 - accuracy: 0.8483 - val_loss: 0.3530 - val_accuracy: 0.8340\n",
            "Epoch 56/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3384 - accuracy: 0.8489 - val_loss: 0.3600 - val_accuracy: 0.8330\n",
            "Epoch 57/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3347 - accuracy: 0.8477 - val_loss: 0.3541 - val_accuracy: 0.8320\n",
            "Epoch 58/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3313 - accuracy: 0.8493 - val_loss: 0.3633 - val_accuracy: 0.8260\n",
            "Epoch 59/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3314 - accuracy: 0.8581 - val_loss: 0.3648 - val_accuracy: 0.8360\n",
            "Epoch 60/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3404 - accuracy: 0.8441 - val_loss: 0.3970 - val_accuracy: 0.8120\n",
            "Epoch 61/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3197 - accuracy: 0.8548 - val_loss: 0.3511 - val_accuracy: 0.8320\n",
            "Epoch 62/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3288 - accuracy: 0.8505 - val_loss: 0.3582 - val_accuracy: 0.8370\n",
            "Epoch 63/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3305 - accuracy: 0.8599 - val_loss: 0.3602 - val_accuracy: 0.8250\n",
            "Epoch 64/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3189 - accuracy: 0.8609 - val_loss: 0.3587 - val_accuracy: 0.8350\n",
            "Epoch 65/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3187 - accuracy: 0.8638 - val_loss: 0.3662 - val_accuracy: 0.8300\n",
            "Epoch 66/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3262 - accuracy: 0.8562 - val_loss: 0.3497 - val_accuracy: 0.8370\n",
            "Epoch 67/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3277 - accuracy: 0.8561 - val_loss: 0.3844 - val_accuracy: 0.8230\n",
            "Epoch 68/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3276 - accuracy: 0.8602 - val_loss: 0.3625 - val_accuracy: 0.8370\n",
            "Epoch 69/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3228 - accuracy: 0.8567 - val_loss: 0.3746 - val_accuracy: 0.8240\n",
            "Epoch 70/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3189 - accuracy: 0.8590 - val_loss: 0.3546 - val_accuracy: 0.8330\n",
            "Epoch 71/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3187 - accuracy: 0.8544 - val_loss: 0.3561 - val_accuracy: 0.8370\n",
            "Epoch 72/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3145 - accuracy: 0.8621 - val_loss: 0.3514 - val_accuracy: 0.8350\n",
            "Epoch 73/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3106 - accuracy: 0.8612 - val_loss: 0.3784 - val_accuracy: 0.8320\n",
            "Epoch 74/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3199 - accuracy: 0.8588 - val_loss: 0.3664 - val_accuracy: 0.8250\n",
            "Epoch 75/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3045 - accuracy: 0.8675 - val_loss: 0.3672 - val_accuracy: 0.8210\n",
            "Epoch 76/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3048 - accuracy: 0.8632 - val_loss: 0.3744 - val_accuracy: 0.8250\n",
            "Epoch 77/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3076 - accuracy: 0.8686 - val_loss: 0.3681 - val_accuracy: 0.8350\n",
            "Epoch 78/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3100 - accuracy: 0.8660 - val_loss: 0.3608 - val_accuracy: 0.8290\n",
            "Epoch 79/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3076 - accuracy: 0.8636 - val_loss: 0.3691 - val_accuracy: 0.8370\n",
            "Epoch 80/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3089 - accuracy: 0.8648 - val_loss: 0.3629 - val_accuracy: 0.8320\n",
            "Epoch 81/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3064 - accuracy: 0.8699 - val_loss: 0.3749 - val_accuracy: 0.8350\n",
            "Epoch 82/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3095 - accuracy: 0.8578 - val_loss: 0.3822 - val_accuracy: 0.8310\n",
            "Epoch 83/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3043 - accuracy: 0.8710 - val_loss: 0.3711 - val_accuracy: 0.8270\n",
            "Epoch 84/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2965 - accuracy: 0.8686 - val_loss: 0.3649 - val_accuracy: 0.8320\n",
            "Epoch 85/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3145 - accuracy: 0.8624 - val_loss: 0.3683 - val_accuracy: 0.8260\n",
            "Epoch 86/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2997 - accuracy: 0.8707 - val_loss: 0.3829 - val_accuracy: 0.8320\n",
            "Epoch 87/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2996 - accuracy: 0.8712 - val_loss: 0.3927 - val_accuracy: 0.8300\n",
            "Epoch 88/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2988 - accuracy: 0.8661 - val_loss: 0.3853 - val_accuracy: 0.8280\n",
            "Epoch 89/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2970 - accuracy: 0.8676 - val_loss: 0.3757 - val_accuracy: 0.8260\n",
            "Epoch 90/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2887 - accuracy: 0.8682 - val_loss: 0.3869 - val_accuracy: 0.8190\n",
            "Epoch 91/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2922 - accuracy: 0.8750 - val_loss: 0.3787 - val_accuracy: 0.8310\n",
            "Epoch 92/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2964 - accuracy: 0.8703 - val_loss: 0.3858 - val_accuracy: 0.8270\n",
            "Epoch 93/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2953 - accuracy: 0.8704 - val_loss: 0.3835 - val_accuracy: 0.8250\n",
            "Epoch 94/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2996 - accuracy: 0.8691 - val_loss: 0.3924 - val_accuracy: 0.8210\n",
            "Epoch 95/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2962 - accuracy: 0.8652 - val_loss: 0.4046 - val_accuracy: 0.8280\n",
            "Epoch 96/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3066 - accuracy: 0.8640 - val_loss: 0.3978 - val_accuracy: 0.8280\n",
            "Epoch 97/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2872 - accuracy: 0.8740 - val_loss: 0.3752 - val_accuracy: 0.8310\n",
            "Epoch 98/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2993 - accuracy: 0.8723 - val_loss: 0.4135 - val_accuracy: 0.8230\n",
            "Epoch 99/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2899 - accuracy: 0.8765 - val_loss: 0.4039 - val_accuracy: 0.8240\n",
            "Epoch 100/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2921 - accuracy: 0.8689 - val_loss: 0.4116 - val_accuracy: 0.8300\n",
            "Epoch 101/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2851 - accuracy: 0.8755 - val_loss: 0.3907 - val_accuracy: 0.8280\n",
            "Epoch 102/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2910 - accuracy: 0.8751 - val_loss: 0.4134 - val_accuracy: 0.8240\n",
            "Epoch 103/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2896 - accuracy: 0.8777 - val_loss: 0.4183 - val_accuracy: 0.8180\n",
            "Epoch 104/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2858 - accuracy: 0.8781 - val_loss: 0.3900 - val_accuracy: 0.8270\n",
            "Epoch 105/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2788 - accuracy: 0.8746 - val_loss: 0.4167 - val_accuracy: 0.8210\n",
            "Epoch 106/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2872 - accuracy: 0.8758 - val_loss: 0.3893 - val_accuracy: 0.8270\n",
            "Epoch 107/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2980 - accuracy: 0.8717 - val_loss: 0.4021 - val_accuracy: 0.8300\n",
            "Epoch 108/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2796 - accuracy: 0.8834 - val_loss: 0.3987 - val_accuracy: 0.8270\n",
            "Epoch 109/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2824 - accuracy: 0.8844 - val_loss: 0.3885 - val_accuracy: 0.8270\n",
            "Epoch 110/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2959 - accuracy: 0.8688 - val_loss: 0.3958 - val_accuracy: 0.8270\n",
            "Epoch 111/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2797 - accuracy: 0.8759 - val_loss: 0.4105 - val_accuracy: 0.8270\n",
            "Epoch 112/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2753 - accuracy: 0.8841 - val_loss: 0.3954 - val_accuracy: 0.8290\n",
            "Epoch 113/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2773 - accuracy: 0.8818 - val_loss: 0.4034 - val_accuracy: 0.8330\n",
            "Epoch 114/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2767 - accuracy: 0.8817 - val_loss: 0.4325 - val_accuracy: 0.8260\n",
            "Epoch 115/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2904 - accuracy: 0.8723 - val_loss: 0.4274 - val_accuracy: 0.8350\n",
            "Epoch 116/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2730 - accuracy: 0.8878 - val_loss: 0.4047 - val_accuracy: 0.8350\n",
            "Epoch 117/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2695 - accuracy: 0.8887 - val_loss: 0.4196 - val_accuracy: 0.8310\n",
            "Epoch 118/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2836 - accuracy: 0.8794 - val_loss: 0.4624 - val_accuracy: 0.8230\n",
            "Epoch 119/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2802 - accuracy: 0.8777 - val_loss: 0.4074 - val_accuracy: 0.8290\n",
            "Epoch 120/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2713 - accuracy: 0.8813 - val_loss: 0.3992 - val_accuracy: 0.8330\n",
            "Epoch 121/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2675 - accuracy: 0.8837 - val_loss: 0.4108 - val_accuracy: 0.8340\n",
            "Epoch 122/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2743 - accuracy: 0.8834 - val_loss: 0.4286 - val_accuracy: 0.8320\n",
            "Epoch 123/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2749 - accuracy: 0.8840 - val_loss: 0.4347 - val_accuracy: 0.8280\n",
            "Epoch 124/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2686 - accuracy: 0.8866 - val_loss: 0.4254 - val_accuracy: 0.8290\n",
            "Epoch 125/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2692 - accuracy: 0.8848 - val_loss: 0.4175 - val_accuracy: 0.8230\n",
            "Epoch 126/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2741 - accuracy: 0.8812 - val_loss: 0.4422 - val_accuracy: 0.8210\n",
            "Epoch 127/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2760 - accuracy: 0.8828 - val_loss: 0.4308 - val_accuracy: 0.8200\n",
            "Epoch 128/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2700 - accuracy: 0.8859 - val_loss: 0.4223 - val_accuracy: 0.8270\n",
            "Epoch 129/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2651 - accuracy: 0.8900 - val_loss: 0.4030 - val_accuracy: 0.8190\n",
            "Epoch 130/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2698 - accuracy: 0.8879 - val_loss: 0.4413 - val_accuracy: 0.8200\n",
            "Epoch 131/250\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2663 - accuracy: 0.8878 - val_loss: 0.4347 - val_accuracy: 0.8230\n",
            "Epoch 132/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2653 - accuracy: 0.8836 - val_loss: 0.4273 - val_accuracy: 0.8270\n",
            "Epoch 133/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2623 - accuracy: 0.8880 - val_loss: 0.4275 - val_accuracy: 0.8220\n",
            "Epoch 134/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2714 - accuracy: 0.8837 - val_loss: 0.4127 - val_accuracy: 0.8250\n",
            "Epoch 135/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2644 - accuracy: 0.8890 - val_loss: 0.4442 - val_accuracy: 0.8190\n",
            "Epoch 136/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2770 - accuracy: 0.8844 - val_loss: 0.4908 - val_accuracy: 0.8190\n",
            "Epoch 137/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2851 - accuracy: 0.8775 - val_loss: 0.4583 - val_accuracy: 0.8240\n",
            "Epoch 138/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2706 - accuracy: 0.8859 - val_loss: 0.4205 - val_accuracy: 0.8280\n",
            "Epoch 139/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2614 - accuracy: 0.8869 - val_loss: 0.4211 - val_accuracy: 0.8310\n",
            "Epoch 140/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2665 - accuracy: 0.8876 - val_loss: 0.4663 - val_accuracy: 0.8250\n",
            "Epoch 141/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2711 - accuracy: 0.8839 - val_loss: 0.4131 - val_accuracy: 0.8290\n",
            "Epoch 142/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2534 - accuracy: 0.8913 - val_loss: 0.4224 - val_accuracy: 0.8210\n",
            "Epoch 143/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2627 - accuracy: 0.8852 - val_loss: 0.4468 - val_accuracy: 0.8240\n",
            "Epoch 144/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2633 - accuracy: 0.8853 - val_loss: 0.4277 - val_accuracy: 0.8190\n",
            "Epoch 145/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2664 - accuracy: 0.8889 - val_loss: 0.4484 - val_accuracy: 0.8240\n",
            "Epoch 146/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2564 - accuracy: 0.8925 - val_loss: 0.4210 - val_accuracy: 0.8310\n",
            "Epoch 147/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2614 - accuracy: 0.8901 - val_loss: 0.4333 - val_accuracy: 0.8190\n",
            "Epoch 148/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2606 - accuracy: 0.8899 - val_loss: 0.4929 - val_accuracy: 0.8280\n",
            "Epoch 149/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2555 - accuracy: 0.8925 - val_loss: 0.4358 - val_accuracy: 0.8310\n",
            "Epoch 150/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2796 - accuracy: 0.8821 - val_loss: 0.4426 - val_accuracy: 0.8310\n",
            "Epoch 151/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2577 - accuracy: 0.8940 - val_loss: 0.4564 - val_accuracy: 0.8250\n",
            "Epoch 152/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2582 - accuracy: 0.8937 - val_loss: 0.4570 - val_accuracy: 0.8350\n",
            "Epoch 153/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2555 - accuracy: 0.8947 - val_loss: 0.4817 - val_accuracy: 0.8210\n",
            "Epoch 154/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2543 - accuracy: 0.8943 - val_loss: 0.4361 - val_accuracy: 0.8340\n",
            "Epoch 155/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2624 - accuracy: 0.8925 - val_loss: 0.4641 - val_accuracy: 0.8230\n",
            "Epoch 156/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2442 - accuracy: 0.8993 - val_loss: 0.4467 - val_accuracy: 0.8260\n",
            "Epoch 157/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2518 - accuracy: 0.8955 - val_loss: 0.4918 - val_accuracy: 0.8180\n",
            "Epoch 158/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2604 - accuracy: 0.8915 - val_loss: 0.4754 - val_accuracy: 0.8250\n",
            "Epoch 159/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2643 - accuracy: 0.8829 - val_loss: 0.4526 - val_accuracy: 0.8370\n",
            "Epoch 160/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2591 - accuracy: 0.8896 - val_loss: 0.4657 - val_accuracy: 0.8250\n",
            "Epoch 161/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2462 - accuracy: 0.8932 - val_loss: 0.4674 - val_accuracy: 0.8300\n",
            "Epoch 162/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2487 - accuracy: 0.8952 - val_loss: 0.4486 - val_accuracy: 0.8270\n",
            "Epoch 163/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2685 - accuracy: 0.8854 - val_loss: 0.4513 - val_accuracy: 0.8240\n",
            "Epoch 164/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2580 - accuracy: 0.8943 - val_loss: 0.4447 - val_accuracy: 0.8330\n",
            "Epoch 165/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2469 - accuracy: 0.8973 - val_loss: 0.4543 - val_accuracy: 0.8270\n",
            "Epoch 166/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2440 - accuracy: 0.8973 - val_loss: 0.4520 - val_accuracy: 0.8390\n",
            "Epoch 167/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2548 - accuracy: 0.8910 - val_loss: 0.4544 - val_accuracy: 0.8280\n",
            "Epoch 168/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2460 - accuracy: 0.8988 - val_loss: 0.4708 - val_accuracy: 0.8210\n",
            "Epoch 169/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2479 - accuracy: 0.8950 - val_loss: 0.4470 - val_accuracy: 0.8250\n",
            "Epoch 170/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2470 - accuracy: 0.8980 - val_loss: 0.4829 - val_accuracy: 0.8370\n",
            "Epoch 171/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2538 - accuracy: 0.8960 - val_loss: 0.4204 - val_accuracy: 0.8280\n",
            "Epoch 172/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2569 - accuracy: 0.8929 - val_loss: 0.4748 - val_accuracy: 0.8250\n",
            "Epoch 173/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2669 - accuracy: 0.8864 - val_loss: 0.4696 - val_accuracy: 0.8290\n",
            "Epoch 174/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2519 - accuracy: 0.8940 - val_loss: 0.4677 - val_accuracy: 0.8260\n",
            "Epoch 175/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2575 - accuracy: 0.8913 - val_loss: 0.4585 - val_accuracy: 0.8310\n",
            "Epoch 176/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2407 - accuracy: 0.9003 - val_loss: 0.4529 - val_accuracy: 0.8280\n",
            "Epoch 177/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2364 - accuracy: 0.9046 - val_loss: 0.4319 - val_accuracy: 0.8360\n",
            "Epoch 178/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2464 - accuracy: 0.8932 - val_loss: 0.4738 - val_accuracy: 0.8250\n",
            "Epoch 179/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2465 - accuracy: 0.8972 - val_loss: 0.4821 - val_accuracy: 0.8370\n",
            "Epoch 180/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2507 - accuracy: 0.8958 - val_loss: 0.4214 - val_accuracy: 0.8340\n",
            "Epoch 181/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2369 - accuracy: 0.9026 - val_loss: 0.4439 - val_accuracy: 0.8340\n",
            "Epoch 182/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2503 - accuracy: 0.8995 - val_loss: 0.4420 - val_accuracy: 0.8340\n",
            "Epoch 183/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2402 - accuracy: 0.9012 - val_loss: 0.5007 - val_accuracy: 0.8220\n",
            "Epoch 184/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2383 - accuracy: 0.9027 - val_loss: 0.4630 - val_accuracy: 0.8250\n",
            "Epoch 185/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2316 - accuracy: 0.9039 - val_loss: 0.4439 - val_accuracy: 0.8260\n",
            "Epoch 186/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2385 - accuracy: 0.9017 - val_loss: 0.4179 - val_accuracy: 0.8400\n",
            "Epoch 187/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2351 - accuracy: 0.9088 - val_loss: 0.4545 - val_accuracy: 0.8350\n",
            "Epoch 188/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2287 - accuracy: 0.9052 - val_loss: 0.4185 - val_accuracy: 0.8380\n",
            "Epoch 189/250\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.2265 - accuracy: 0.9049 - val_loss: 0.4457 - val_accuracy: 0.8420\n",
            "Epoch 190/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2347 - accuracy: 0.9052 - val_loss: 0.4444 - val_accuracy: 0.8250\n",
            "Epoch 191/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2363 - accuracy: 0.9022 - val_loss: 0.4832 - val_accuracy: 0.8350\n",
            "Epoch 192/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2402 - accuracy: 0.9041 - val_loss: 0.4245 - val_accuracy: 0.8450\n",
            "Epoch 193/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2398 - accuracy: 0.9023 - val_loss: 0.4430 - val_accuracy: 0.8400\n",
            "Epoch 194/250\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2297 - accuracy: 0.9063 - val_loss: 0.4254 - val_accuracy: 0.8400\n",
            "Epoch 195/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2370 - accuracy: 0.9043 - val_loss: 0.4277 - val_accuracy: 0.8410\n",
            "Epoch 196/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2314 - accuracy: 0.9075 - val_loss: 0.3943 - val_accuracy: 0.8390\n",
            "Epoch 197/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2105 - accuracy: 0.9123 - val_loss: 0.4057 - val_accuracy: 0.8370\n",
            "Epoch 198/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2304 - accuracy: 0.9049 - val_loss: 0.4110 - val_accuracy: 0.8410\n",
            "Epoch 199/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2262 - accuracy: 0.9076 - val_loss: 0.4308 - val_accuracy: 0.8440\n",
            "Epoch 200/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2161 - accuracy: 0.9103 - val_loss: 0.4107 - val_accuracy: 0.8490\n",
            "Epoch 201/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2105 - accuracy: 0.9143 - val_loss: 0.4033 - val_accuracy: 0.8460\n",
            "Epoch 202/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2162 - accuracy: 0.9119 - val_loss: 0.4226 - val_accuracy: 0.8460\n",
            "Epoch 203/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2166 - accuracy: 0.9122 - val_loss: 0.4048 - val_accuracy: 0.8460\n",
            "Epoch 204/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1990 - accuracy: 0.9167 - val_loss: 0.3810 - val_accuracy: 0.8580\n",
            "Epoch 205/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2122 - accuracy: 0.9168 - val_loss: 0.4074 - val_accuracy: 0.8480\n",
            "Epoch 206/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2007 - accuracy: 0.9202 - val_loss: 0.4105 - val_accuracy: 0.8590\n",
            "Epoch 207/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1982 - accuracy: 0.9234 - val_loss: 0.3732 - val_accuracy: 0.8680\n",
            "Epoch 208/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2071 - accuracy: 0.9146 - val_loss: 0.3724 - val_accuracy: 0.8700\n",
            "Epoch 209/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2026 - accuracy: 0.9220 - val_loss: 0.3935 - val_accuracy: 0.8610\n",
            "Epoch 210/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1973 - accuracy: 0.9247 - val_loss: 0.3747 - val_accuracy: 0.8610\n",
            "Epoch 211/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1942 - accuracy: 0.9251 - val_loss: 0.3582 - val_accuracy: 0.8620\n",
            "Epoch 212/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1966 - accuracy: 0.9260 - val_loss: 0.3714 - val_accuracy: 0.8670\n",
            "Epoch 213/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1886 - accuracy: 0.9294 - val_loss: 0.3653 - val_accuracy: 0.8680\n",
            "Epoch 214/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2028 - accuracy: 0.9192 - val_loss: 0.3668 - val_accuracy: 0.8620\n",
            "Epoch 215/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1847 - accuracy: 0.9258 - val_loss: 0.3683 - val_accuracy: 0.8660\n",
            "Epoch 216/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1961 - accuracy: 0.9247 - val_loss: 0.3352 - val_accuracy: 0.8760\n",
            "Epoch 217/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1837 - accuracy: 0.9293 - val_loss: 0.3594 - val_accuracy: 0.8750\n",
            "Epoch 218/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1857 - accuracy: 0.9275 - val_loss: 0.3501 - val_accuracy: 0.8750\n",
            "Epoch 219/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1828 - accuracy: 0.9292 - val_loss: 0.3565 - val_accuracy: 0.8710\n",
            "Epoch 220/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1637 - accuracy: 0.9396 - val_loss: 0.3280 - val_accuracy: 0.8870\n",
            "Epoch 221/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1920 - accuracy: 0.9275 - val_loss: 0.3192 - val_accuracy: 0.8930\n",
            "Epoch 222/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1804 - accuracy: 0.9299 - val_loss: 0.3234 - val_accuracy: 0.8880\n",
            "Epoch 223/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1642 - accuracy: 0.9349 - val_loss: 0.3488 - val_accuracy: 0.8800\n",
            "Epoch 224/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1667 - accuracy: 0.9369 - val_loss: 0.3436 - val_accuracy: 0.8860\n",
            "Epoch 225/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1672 - accuracy: 0.9372 - val_loss: 0.3297 - val_accuracy: 0.8920\n",
            "Epoch 226/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1778 - accuracy: 0.9279 - val_loss: 0.3159 - val_accuracy: 0.8900\n",
            "Epoch 227/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1580 - accuracy: 0.9377 - val_loss: 0.3422 - val_accuracy: 0.8860\n",
            "Epoch 228/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1637 - accuracy: 0.9389 - val_loss: 0.3227 - val_accuracy: 0.8960\n",
            "Epoch 229/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1621 - accuracy: 0.9362 - val_loss: 0.3558 - val_accuracy: 0.8790\n",
            "Epoch 230/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1730 - accuracy: 0.9362 - val_loss: 0.3718 - val_accuracy: 0.8810\n",
            "Epoch 231/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1712 - accuracy: 0.9361 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
            "Epoch 232/250\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.1663 - accuracy: 0.9376 - val_loss: 0.3646 - val_accuracy: 0.8830\n",
            "Epoch 233/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1725 - accuracy: 0.9364 - val_loss: 0.3053 - val_accuracy: 0.8770\n",
            "Epoch 234/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1585 - accuracy: 0.9384 - val_loss: 0.3213 - val_accuracy: 0.8940\n",
            "Epoch 235/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1545 - accuracy: 0.9451 - val_loss: 0.3506 - val_accuracy: 0.8840\n",
            "Epoch 236/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1592 - accuracy: 0.9357 - val_loss: 0.3479 - val_accuracy: 0.8850\n",
            "Epoch 237/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1615 - accuracy: 0.9427 - val_loss: 0.3290 - val_accuracy: 0.8880\n",
            "Epoch 238/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1518 - accuracy: 0.9441 - val_loss: 0.3193 - val_accuracy: 0.8910\n",
            "Epoch 239/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1795 - accuracy: 0.9367 - val_loss: 0.3298 - val_accuracy: 0.8900\n",
            "Epoch 240/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1702 - accuracy: 0.9389 - val_loss: 0.3029 - val_accuracy: 0.8880\n",
            "Epoch 241/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1497 - accuracy: 0.9440 - val_loss: 0.3199 - val_accuracy: 0.9000\n",
            "Epoch 242/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1607 - accuracy: 0.9389 - val_loss: 0.3040 - val_accuracy: 0.8990\n",
            "Epoch 243/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1495 - accuracy: 0.9467 - val_loss: 0.3007 - val_accuracy: 0.8940\n",
            "Epoch 244/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1602 - accuracy: 0.9421 - val_loss: 0.3030 - val_accuracy: 0.8980\n",
            "Epoch 245/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1627 - accuracy: 0.9403 - val_loss: 0.3173 - val_accuracy: 0.8960\n",
            "Epoch 246/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1533 - accuracy: 0.9423 - val_loss: 0.3170 - val_accuracy: 0.8960\n",
            "Epoch 247/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1446 - accuracy: 0.9446 - val_loss: 0.2981 - val_accuracy: 0.9020\n",
            "Epoch 248/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1552 - accuracy: 0.9446 - val_loss: 0.3449 - val_accuracy: 0.8780\n",
            "Epoch 249/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1400 - accuracy: 0.9497 - val_loss: 0.3254 - val_accuracy: 0.8860\n",
            "Epoch 250/250\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.1504 - accuracy: 0.9431 - val_loss: 0.3265 - val_accuracy: 0.8990\n",
            "Training took 20.430507822831473 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z7mmZTW6sGc"
      },
      "source": [
        "**4.2 Save the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlUrAmQY8Bcq"
      },
      "source": [
        "filename = 'my_chatbot_250_epochs.h5'\r\n",
        "model.save(filename)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FUPbA4E62Yu"
      },
      "source": [
        "# **Part 5 - Evaluating the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s27gXP2D650I"
      },
      "source": [
        "**5.1 Plotting Out Training History**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "_XJdmkOD60OA",
        "outputId": "09df2abf-fefd-46ed-87e0-ea13299ddda4"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "print(history.history.keys())\r\n",
        "# summarize history for accuracy\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdYqtiV_8Nm-"
      },
      "source": [
        "**5.2 Loading The Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE8akYIe-wPI"
      },
      "source": [
        "model.load_weights('my_chatbot_250_epochs.h5')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkO60OaC7jxx"
      },
      "source": [
        "**5.3 Evaluating on Given Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5siYkITy6_Bh"
      },
      "source": [
        "pred_results = model.predict(([inputs_test, queries_test])) #passing in our two test inputs"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6b20CPh81me",
        "outputId": "c534574b-0331-444e-cf16-15cefdd9ad86"
      },
      "source": [
        "print(' '.join(test_data[0][0])) #recall entry 0, index 0 is the first story\r\n",
        "print(' '.join(test_data[0][1])) #recall entry 0, index 1 is the first question\r\n",
        "print(test_data[0][2]) #recall entry 0, index 2 is first answer"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n",
            "Is John in the kitchen ?\n",
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7_l98px9Cdc",
        "outputId": "ee4f3696-376e-4801-f066-0953846ef344"
      },
      "source": [
        "print(pred_results[0]) #notice how it has probabilities for every word, not just yes and no\r\n",
        "print(pred_results.shape) #so see the 37 vocab words + 1 for padding, all 37 vocab words have a probability (close to 0 tho except for yes and no)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.0161626e-17 3.5168613e-17 3.8314351e-17 2.9720646e-17 9.9967730e-01\n",
            " 2.5605263e-17 2.5219640e-17 2.9729265e-17 2.4174977e-17 2.7764790e-17\n",
            " 3.3919004e-17 3.3250646e-17 3.2268927e-04 3.0361684e-17 3.2819039e-17\n",
            " 2.6714688e-17 3.1879640e-17 2.7216659e-17 3.0434853e-17 2.9166706e-17\n",
            " 2.5730495e-17 2.6649648e-17 3.1609354e-17 2.7160859e-17 3.3457530e-17\n",
            " 2.8102363e-17 2.7457551e-17 2.9897924e-17 3.0924749e-17 3.5755842e-17\n",
            " 3.3182727e-17 2.9424297e-17 2.8695355e-17 3.4550543e-17 2.6811369e-17\n",
            " 3.9472414e-17 3.1940259e-17 3.1847794e-17]\n",
            "(1000, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LBWssXoW9i1B",
        "outputId": "6e3d05ee-a0e5-4c02-fcf6-4451b3bff8d8"
      },
      "source": [
        "val_max = np.argmax(pred_results[0])\r\n",
        "\r\n",
        "for key,val in tokenizer.word_index.items():\r\n",
        "  #just grabbing the key (word index) and val (word) from the dictionary given by .word_index\r\n",
        "  if val == val_max:\r\n",
        "    k = key\r\n",
        "\r\n",
        "k"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D271nMNU-FU6",
        "outputId": "251dc9f4-274a-4708-cd1d-d6e0c5ed675f"
      },
      "source": [
        "pred_results[0][val_max] #so it was 99.9% sure the answer was no"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9996773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQwiZPd--c9E"
      },
      "source": [
        "**5.4 Testing on Our Own Story**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg03K67zVTkL"
      },
      "source": [
        "5.4.1 Story 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h9KHiyC-Uis",
        "outputId": "4840d03c-6a1e-48c6-8730-23de773e47e5"
      },
      "source": [
        "my_story = \"John travelled to the office . Sandra discarded the apple in the kitchen .\"\r\n",
        "my_story = my_story.split() #now splitting up each word in my_story\r\n",
        "print(my_story)\r\n",
        "#print(' '.join(my_story)) "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['John', 'travelled', 'to', 'the', 'office', '.', 'Sandra', 'discarded', 'the', 'apple', 'in', 'the', 'kitchen', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkTeBSYo-yJY",
        "outputId": "8cc1df1a-0938-4c7f-a6a5-643c9504c9d5"
      },
      "source": [
        "my_question = \"Is Sandra in the office ?\"\r\n",
        "my_question = my_question.split()\r\n",
        "my_question"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'Sandra', 'in', 'the', 'office', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZlicje9-2k4"
      },
      "source": [
        "mydata = [(my_story, my_question, 'yes')] #so now adding our story, question, and label into one list"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KsQCFZT_VcK",
        "outputId": "8e6190d0-c285-4c0b-973f-37a57f33ba16"
      },
      "source": [
        "my_story, my_ques, my_ans = vectorize(mydata) #utilizing our vectorize function from above to vectorize our story, question, and answer\r\n",
        "\r\n",
        "my_story #see it's the story replaced with the word indexes, also padded by 0s to meet the max length"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11, 28,\n",
              "        17, 31, 23,  5, 21, 18, 31, 32,  8, 31, 10,  5]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcKqVMUX_kDI",
        "outputId": "70576045-a12c-43a5-9aa0-f27e455c229b"
      },
      "source": [
        "pred_results = model.predict(([my_story, my_ques])) #passing in our two test inputs\r\n",
        "\r\n",
        "val_max = np.argmax(pred_results[0])\r\n",
        "\r\n",
        "for key,val in tokenizer.word_index.items():\r\n",
        "  #just grabbing the key (word index) and val (word) from the dictionary given by .word_index\r\n",
        "  if val == val_max:\r\n",
        "    k = key\r\n",
        "\r\n",
        "print(f\"{k} with a {pred_results[0][val_max]*100} probability\") #so it was 99.99% sure the answer was no\""
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no with a 99.99819993972778 probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0X32zANVXV9"
      },
      "source": [
        "5.4.2 Story 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS7TkA_M_4j6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84c662f-0efd-41ab-8062-6d8736e3a4e2"
      },
      "source": [
        "my_story2 = \"Daniel journeyed to the bedroom . Mary grabbed the football in the office .\"\r\n",
        "my_story2 = my_story2.split() #now splitting up each word in my_story\r\n",
        "\r\n",
        "my_question2 = \"Is the football in the office ?\"\r\n",
        "my_question2 = my_question2.split()\r\n",
        "\r\n",
        "mydata2 = [(my_story2, my_question2, 'yes')] #so now adding our story, question, and label into one list\r\n",
        "\r\n",
        "my_story2, my_ques2, my_ans2 = vectorize(mydata2) #utilizing our vectorize function from above to vectorize our story, question, and answer\r\n",
        "\r\n",
        "pred_results = model.predict(([my_story2, my_ques2])) #passing in our two test inputs\r\n",
        "\r\n",
        "val_max = np.argmax(pred_results[0])\r\n",
        "\r\n",
        "for key,val in tokenizer.word_index.items():\r\n",
        "  #just grabbing the key (word index) and val (word) from the dictionary given by .word_index\r\n",
        "  if val == val_max:\r\n",
        "    k = key\r\n",
        "\r\n",
        "print(f\"{k} with a {pred_results[0][val_max]*100} probability\") #so it was 53.7% sure the answer was yes\""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yes with a 53.699856996536255 probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe8SC8m6WlgX"
      },
      "source": [
        "5.4.3 Story 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfeRc5_mVcMD",
        "outputId": "06177171-ce27-4e6f-eba1-3f4e34227c37"
      },
      "source": [
        "my_story3 = \"Sandra is in the hallway . Daniel picked up apple in the garden .\"\r\n",
        "my_story3 = my_story3.split() #now splitting up each word in my_story\r\n",
        "\r\n",
        "my_question3 = \"Is the apple in the hallway ?\"\r\n",
        "my_question3 = my_question3.split()\r\n",
        "\r\n",
        "mydata3 = [(my_story3, my_question3, 'no')] #so now adding our story, question, and label into one list\r\n",
        "\r\n",
        "my_story3, my_ques3, my_ans3 = vectorize(mydata3) #utilizing our vectorize function from above to vectorize our story, question, and answer\r\n",
        "\r\n",
        "pred_results = model.predict(([my_story3, my_ques3])) #passing in our two test inputs\r\n",
        "\r\n",
        "val_max = np.argmax(pred_results[0])\r\n",
        "\r\n",
        "for key,val in tokenizer.word_index.items():\r\n",
        "  #just grabbing the key (word index) and val (word) from the dictionary given by .word_index\r\n",
        "  if val == val_max:\r\n",
        "    k = key\r\n",
        "\r\n",
        "print(f\"{k} with a {pred_results[0][val_max]*100} probability\") #so it was 99% sure the answer was no\""
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no with a 99.92278814315796 probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvM_zoJBXy43"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
